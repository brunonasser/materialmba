{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "## <span style=\"color:darkred\">Avaliação Final</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa avaliação será utilizado o dataset `smartphone_activity.csv` que contém 561 colunas, cujo objetivo é classificar uma entre 6 ações de uma pessoa com base em sensores disponíveis no smartphone. Vamos assumir um cenário com alta disponibilidade de exemplos não rotulados, e baixa de exemplos rotulados. Para tal, pré-treinaremos camadas de uma rede neural com dados não anotados, a qual posteriormente será usada para compor um modelo inicial de classificação.\n",
    "\n",
    "Conforme código abaixo, use como características de entrada as 561 primeiras colunas e como classe a última coluna (activity). \n",
    "\n",
    "As tarefas a realizar são as seguintes:\n",
    "\n",
    "1. **Prepare** os dados conforme o código fornecido (leia abaixo e estude o código para entender):\n",
    "    * carregue o dataset e organize as features e rótulos\n",
    "    * conjunto S = 2% dos dados iniciais como treinamento com rótulo (assumiremos que temos rótulos apenas para esses 2%), no formato par (x,y)\n",
    "    * conjunto U = 50% dos dados iniciais como treinamento não anotado (note que S está contido em U), \n",
    "    * conjunto T = o restante dos 50% para teste, no formato par (x,y).<br><br>\n",
    "    \n",
    "1.  (3,0 pt) **Modelo A**: projete e treine um undercomplete autoencoder com dropout na entrada para pré-treinamento baseado em auto-supervisão. Esse autoencoder aprende a preencher os valores eliminados na camada de entrada. A arquitetura deve ter a seguinte estrutura:\n",
    "    1. Encoder:\n",
    "        * entrada com 561 valores\n",
    "        * dropout com taxa de 0.25\n",
    "        * normalização em batch\n",
    "        * densa 256 neurônios, relu\n",
    "        * densa 256 neurônios, relu\n",
    "        * densa 64 neurônios, ativação linear \n",
    "        * normalização em batch (consideraremos essa camada como sendo o código produzido pelo encoder)\n",
    "        * ativação relu\n",
    "        * dropout 0.25\n",
    "    2. Decoder:\n",
    "        * densa 256 neurônios, ativação tanh\n",
    "        * densa 256 neurônios, ativação tanh\n",
    "        * densa 561 neurônios, ativação tanh\n",
    "    * Usar Adam com taxa de aprendizado inicial de 0.005 e com decaimento exponencial a -0.1<br>\n",
    "    * Treinar com perda MSE por 20 épocas com batch size 16 utilizando o conjunto **U**<br>\n",
    "    * Exiba a perda final MSE após as 20 utilizando o conjunto **U** (use o evaluate para isso)<br>\n",
    "    * Obtenha o código (saída do encoder relativa a normalização em batch após a camada de 64 dimensões) para os dados de treinamento (conjunto **U**) e armazene-o num array `code_train`. Exiba na tela esse código para a primeira instância de treinamento (índice 0)<br><br>\n",
    "    \n",
    "1. (3,5 pt)  **Modelo B**: rede neural profunda densa, utilizando como base o encoder do modelo A (inclusive seus pesos pré-treinados), e inserindo uma nova camada densa de classificação (em 6 classes) com ativação softmax (essa inicializada aleatoriamente). Porém **não** deve conter o primeiro dropout (logo após a camada de entrada) do encoder, ou seja a primeira camada dropout deve ser removida.<br>\n",
    "    * A arquitetura deve ter portanto as seguintes camadas:\n",
    "        * entrada\n",
    "        * normalização em batch\n",
    "        * densa 256 neurônios, relu\n",
    "        * densa 256 neurônios, relu\n",
    "        * densa 64 neurônios, ativação linear\n",
    "        * normalização em batch\n",
    "        * ativação relu\n",
    "        * dropout 0.25\n",
    "        * densa 6 neurônios, softmax\n",
    "        \n",
    "    * Utilizar Adam com taxa de aprendizado inicial de 0.001 e com decaimento em todas as épocas exponencial a -0.1\n",
    "    * Treinar com perda entropia cruzada categórica por 50 épocas com batch size 16 \n",
    "    * Compute como métricas, além da perda, precisão e revocação (precision / recall)<br><br>\n",
    "    \n",
    "1. (3,5 pt) **Avalie a rede neural de classificação** (Modelo B): \n",
    "    * Exiba o gráfico da precisão e revocação calculada no treinamento ao longo das épocas para o modelo B\n",
    "    * Exiba precisão e revocação calculada no treinamento S e teste T (use evaluate no modelo B)<br><br>\n",
    "    \n",
    "1. **Bônus:** (+1 ponto extra) \n",
    "    * (0,5) *Análise de projeção das características*: visualize scatterplots com os 2 principais componentes obtidos do PCA com as classes dos exemplos atribuídas com cores ou marcadores diferentes. Projetar em 2D os seguintes espaços:\n",
    "        1. scatterplot com projeção PCA do conjunto de S original (561 dimensões)\n",
    "        1. scatterplot com projeção PCA do código (64 dimensões) do conjunto S após processado pelo \"encoder\" do *Modelo A* (code_train obtido no item/questão 2)\n",
    "        1. scatterplot com projeção PCA do código (64 dimensões) do conjunto S após processado pelo \"encoder\" do *Modelo B* (treinado no item/questão 3)<br><br>    \n",
    "    \n",
    "    * (0,5) Obtenha um classificador SVM com kernel linear, treinado nos dados S obtendo sua representação do código (64 dimensões) da rede de classificação (modelo B). Avalie precisão e revocação no treinamento S e teste T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:22:32.622327: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_553</th>\n",
       "      <th>feature_554</th>\n",
       "      <th>feature_555</th>\n",
       "      <th>feature_556</th>\n",
       "      <th>feature_557</th>\n",
       "      <th>feature_558</th>\n",
       "      <th>feature_559</th>\n",
       "      <th>feature_560</th>\n",
       "      <th>feature_561</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.1330</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.9830</td>\n",
       "      <td>-0.914</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.93500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2990</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.1130</td>\n",
       "      <td>0.03040</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.0586</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.0164</td>\n",
       "      <td>-0.1240</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.9750</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.94300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5950</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>-0.00743</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.0543</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.0195</td>\n",
       "      <td>-0.1130</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.9670</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.93900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3910</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>0.17800</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>-0.1230</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.9830</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.93900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1170</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.0368</td>\n",
       "      <td>-0.01290</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.4850</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.0477</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.1150</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.9810</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.94200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3510</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.6160</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0991</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.1410</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3760</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.3370</td>\n",
       "      <td>0.34600</td>\n",
       "      <td>0.885</td>\n",
       "      <td>-0.6990</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3200</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.7370</td>\n",
       "      <td>-0.37300</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>-0.1160</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.0421</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.00747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.1820</td>\n",
       "      <td>0.08860</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>-0.0965</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.2300</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.00747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2050</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>-0.81900</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>-0.1370</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.1950</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.11200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0722</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>-0.28800</td>\n",
       "      <td>0.876</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10299 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0          0.289    -0.0203    -0.1330     -0.995    -0.9830     -0.914   \n",
       "1          0.278    -0.0164    -0.1240     -0.998    -0.9750     -0.960   \n",
       "2          0.280    -0.0195    -0.1130     -0.995    -0.9670     -0.979   \n",
       "3          0.279    -0.0262    -0.1230     -0.996    -0.9830     -0.991   \n",
       "4          0.277    -0.0166    -0.1150     -0.998    -0.9810     -0.990   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "10294      0.310    -0.0534    -0.0991     -0.288    -0.1410     -0.215   \n",
       "10295      0.363    -0.0392    -0.1060     -0.305     0.0281     -0.196   \n",
       "10296      0.350     0.0301    -0.1160     -0.330    -0.0421     -0.250   \n",
       "10297      0.238     0.0185    -0.0965     -0.323    -0.2300     -0.208   \n",
       "10298      0.154    -0.0184    -0.1370     -0.330    -0.1950     -0.164   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_553  \\\n",
       "0         -0.995     -0.983     -0.924    -0.93500  ...      -0.2990   \n",
       "1         -0.999     -0.975     -0.958    -0.94300  ...      -0.5950   \n",
       "2         -0.997     -0.964     -0.977    -0.93900  ...      -0.3910   \n",
       "3         -0.997     -0.983     -0.989    -0.93900  ...      -0.1170   \n",
       "4         -0.998     -0.980     -0.990    -0.94200  ...      -0.3510   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "10294     -0.356     -0.149     -0.232     0.18500  ...      -0.3760   \n",
       "10295     -0.374     -0.030     -0.270     0.18500  ...      -0.3200   \n",
       "10296     -0.388     -0.133     -0.347     0.00747  ...      -0.1190   \n",
       "10297     -0.392     -0.280     -0.289     0.00747  ...      -0.2050   \n",
       "10298     -0.431     -0.218     -0.230    -0.11200  ...      -0.0722   \n",
       "\n",
       "       feature_554  feature_555  feature_556  feature_557  feature_558  \\\n",
       "0           -0.710      -0.1130      0.03040       -0.465      -0.0184   \n",
       "1           -0.861       0.0535     -0.00743       -0.733       0.7040   \n",
       "2           -0.760      -0.1190      0.17800        0.101       0.8090   \n",
       "3           -0.483      -0.0368     -0.01290        0.640      -0.4850   \n",
       "4           -0.699       0.1230      0.12300        0.694      -0.6160   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10294       -0.751      -0.3370      0.34600        0.885      -0.6990   \n",
       "10295       -0.700      -0.7370     -0.37300       -0.657       0.3230   \n",
       "10296       -0.467      -0.1820      0.08860        0.697       0.3630   \n",
       "10297       -0.618       0.4450     -0.81900        0.929      -0.0084   \n",
       "10298       -0.437       0.5990     -0.28800        0.876      -0.0250   \n",
       "\n",
       "       feature_559  feature_560  feature_561  activity  \n",
       "0           -0.841        0.180      -0.0586         5  \n",
       "1           -0.845        0.180      -0.0543         5  \n",
       "2           -0.849        0.181      -0.0491         5  \n",
       "3           -0.849        0.182      -0.0477         5  \n",
       "4           -0.848        0.185      -0.0439         5  \n",
       "...            ...          ...          ...       ...  \n",
       "10294       -0.652        0.275       0.1850         2  \n",
       "10295       -0.655        0.274       0.1820         2  \n",
       "10296       -0.655        0.274       0.1810         2  \n",
       "10297       -0.660        0.265       0.1880         2  \n",
       "10298       -0.660        0.264       0.1880         2  \n",
       "\n",
       "[10299 rows x 562 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"smartphone_activity_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: separar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 561)\n",
      "Tamanho conjunto de treinamento:  205\n",
      "Tamanho conjunto de treinamento não rotulado:  5149\n",
      "Tamanho conjunto de testes:  5149\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "rotulos = np.array(df['activity'])-1\n",
    "features = np.array(df.iloc[:, :-1])\n",
    "\n",
    "print(features.shape)\n",
    "perc_train = 0.5\n",
    "perc_rot = 0.02\n",
    "\n",
    "n_train_U = int(features.shape[0]*perc_train)\n",
    "n_train_S = int(features.shape[0]*perc_rot)\n",
    "n_test = int(features.shape[0]*(1-perc_train))\n",
    "print(\"Tamanho conjunto de treinamento: \", n_train_S)\n",
    "print(\"Tamanho conjunto de treinamento não rotulado: \", n_train_U)\n",
    "print(\"Tamanho conjunto de testes: \", n_test)\n",
    "\n",
    "x_trainS = features[:n_train_S,:]\n",
    "y_trainS = to_categorical(rotulos[:n_train_S], 6)\n",
    "# rotulos discretos de treinamento\n",
    "rot_trainS = rotulos[:n_train_S]\n",
    "\n",
    "x_trainU = features[:n_train_U,:]\n",
    "y_trainU = to_categorical(rotulos[:n_train_U], 6)\n",
    "\n",
    "x_test = features[n_train_U:,:]\n",
    "y_test = to_categorical(rotulos[n_train_U:], 6)\n",
    "# rotulos discretos de teste\n",
    "rot_test = rotulos[n_train_U:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "### instanciar modelo AE\n",
    "### compilar\n",
    "### treinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### avaliar MSE no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obter código 64d da normalizacao em batch do treinamento\n",
    "### exibir código da primeira instancia do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### criar novo modelo usando encoder pré-treinado do modelo A\n",
    "\n",
    "# dica: obter lista de camadas\n",
    "#layers = [l for l in modelo.layers]\n",
    "\n",
    "# montar novo modelo com nova camada de entrada\n",
    "# adicionar camadas anteriores usando novo_modelo.add(layers[i])\n",
    "# adicionar novas camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compilar modelo B\n",
    "# treinar modelo B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4: Avaliação da rede neural de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibir grafico com precision e recall das épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avalie precision e recall final no treinamento/teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bônus\n",
    "\n",
    "#### 1: Análise do espaço de características aprendido (0,5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# código exemplo para scatterplot (sendo pca_train o array com dados projetados, e rot_train rotulos discretos)\n",
    "scatter = ax.scatter(pca_train[:,0], pca_train[:,1], c=rot_train, cmap=\"jet\")\n",
    "legend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
    "ax.add_artist(legend1)\n",
    "plt.title('PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: SVM no código aprendido (0,5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Exercicios_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
