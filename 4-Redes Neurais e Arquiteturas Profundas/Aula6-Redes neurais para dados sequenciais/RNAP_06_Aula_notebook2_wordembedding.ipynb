{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvaEK6Bn-wwG"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo 6 - Redes neurais para dados sequenciais</span>\n",
    "\n",
    "#### <span style=\"color:darkred\">**Parte 2: Word Embedding**</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wvtQgvYq_z7v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 16:28:15.530357: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hVCHWi9KriW"
   },
   "source": [
    "## Carregando representações pré-treinadas em português \n",
    "\n",
    "Após salvar, vamos montar um dicionário com palavra/vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "2E5iOeI4lqbm",
    "outputId": "da8d9c0d-5364-42cd-b816-9d5bd6e54d19"
   },
   "outputs": [],
   "source": [
    "#!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "-xsQ97N_pmUn",
    "outputId": "f0380e31-9988-4757-d2cf-a343cc053414"
   },
   "outputs": [],
   "source": [
    "#!mv download.php?file=embeddings%2Fglove%2Fglove_s50.zip glove_s50.zip\n",
    "#!unzip -q glove_s50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "KgO7dF4s9D7X",
    "outputId": "0f79d0be-3544-4fcd-b1e0-2fdf474d54da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3841/1001941722.py:11: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  coefs = np.fromstring(coefs, \"f\", sep=\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 929594 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \"/content/glove_s50.txt\" # colab\n",
    ")\n",
    "\n",
    "path_to_glove_file = \"./glove_s50.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Encontrados %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "EBPgAvQHrk-f",
    "outputId": "de4cd802-4270-44e8-aa5a-c322c3b6c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.984870e-01  1.938170e-01  1.839920e-01 -2.590166e+00 -3.155430e-01\n",
      " -1.469410e-01  1.290320e-01  3.814410e-01 -4.846610e-01  3.721310e-01\n",
      "  6.471990e-01 -1.248160e+00 -3.151210e-01  3.676890e-01 -7.965720e-01\n",
      "  2.589710e-01 -1.260200e-02 -6.782460e-01 -4.735670e-01  3.739230e-01\n",
      "  1.437597e+00  2.001800e-02  9.999200e-02 -1.829620e-01  2.779400e-01\n",
      "  1.222500e-01 -2.345070e-01 -7.791430e-01  6.422940e-01  3.167230e-01\n",
      " -3.914640e-01  3.333300e-01  2.291640e-01 -9.465310e-01 -2.157560e-01\n",
      " -3.246800e-02 -3.029230e-01  9.146800e-02 -1.788646e+00 -2.995630e-01\n",
      " -3.183580e-01 -7.586490e-01  2.524000e-03 -6.656960e-01  7.843900e-01\n",
      "  1.341660e-01  6.273990e-01  3.014050e-01 -4.354190e-01  1.121057e+00]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index['aprovação'])\n",
    "print(len(embeddings_index['aprovação']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy0O2L2WK6D7"
   },
   "source": [
    "## Base de dados: rumor Brazil 2018\n",
    "\n",
    "Base de dados de texto para classificação em frases \"falsas\" ou \"verdadeiras\" conforme checado por agências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RNykW-NnniWS",
    "outputId": "9b3863ff-dda5-4dcb-c471-e52229b6c8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Salário Mínimo: R$ 950,00. Bolsa Presidiário: ...\n",
      "1    Empresa contratada pelo TSE para apuração dos ...\n",
      "2    O Aloizio Mercadante, ministro da Educação, mo...\n",
      "3    Há um complô espalhando fake news descaradas e...\n",
      "4    Somente em 2017, mais de 800 milhões de tonela...\n",
      "5    Nunca vi o Lula pronunciar essa palavra fascis...\n",
      "6    O Mourão, por exemplo, foi ele próprio tortura...\n",
      "7    O PSB, todos os seus governadores e o seu pres...\n",
      "8    Bolsonaro Nunca aprovou um projeto de seguranç...\n",
      "9    Ele Lula não pode aparecer mais que 25% no hor...\n",
      "Name: texto, dtype: object\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: rotulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/rumor-election-brazil-2018.csv\", delimiter=';')\n",
    "texto = df['texto']\n",
    "rotulos = (df['rotulo']=='VERDADE').astype(int)\n",
    "\n",
    "class_names = [\"FALSO\", \"VERDADEIRO\"]\n",
    "\n",
    "print(texto[:10])\n",
    "print(rotulos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239 221]\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(rotulos)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "EQ11lJuvFr-i",
    "outputId": "441617a0-6310-4538-90a2-4d18b7dba71b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3841/1092158642.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rng.shuffle(texto)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "rng.shuffle(texto)\n",
    "rng = np.random.RandomState(1)\n",
    "rng.shuffle(rotulos)\n",
    "\n",
    "validation_split = 0.1\n",
    "num_validation = int(validation_split * len(texto))\n",
    "x_train = texto[:-num_validation]\n",
    "x_val = texto[-num_validation:]\n",
    "y_train = rotulos[:-num_validation]\n",
    "y_val = rotulos[-num_validation:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2-a0lZutC7b"
   },
   "source": [
    "Vocabulário irá considerar até 20 mil palavras, e irá truncar sequências com mais de 32 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T-L2MpeWsNx5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 16:28:24.967581: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-28 16:28:25.031839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.032254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 980M computeCapability: 5.2\n",
      "coreClock: 1.1265GHz coreCount: 12 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 149.31GiB/s\n",
      "2021-10-28 16:28:25.032279: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-28 16:28:25.034513: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-28 16:28:25.034567: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-28 16:28:25.035347: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-28 16:28:25.035537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-28 16:28:25.035937: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-28 16:28:25.036583: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-28 16:28:25.036710: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-28 16:28:25.036802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.037147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.037412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-28 16:28:25.037769: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-28 16:28:25.038174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.038511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 980M computeCapability: 5.2\n",
      "coreClock: 1.1265GHz coreCount: 12 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 149.31GiB/s\n",
      "2021-10-28 16:28:25.038563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.038858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.039115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-28 16:28:25.039144: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-28 16:28:25.435664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-28 16:28:25.435687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-28 16:28:25.435693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-28 16:28:25.435867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.436193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.436494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 16:28:25.436768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3364 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\n",
      "2021-10-28 16:28:25.522677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-28 16:28:25.523113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2594955000 Hz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=32)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(16)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-EOJZN3LGFx"
   },
   "source": [
    "Podemos ver o resultado do vetorizador, que exibe 1 para palavras fora do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "h0_DF96isQQI",
    "outputId": "ac69934b-7f35-4758-ab27-32ac58bce0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 92,  1,  1,  1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"um dois one two three\"]])\n",
    "output.numpy()[0, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIRN7jpDLLnW"
   },
   "source": [
    "Abaixo, considerando o número de tokens (palavras) da base de dados, vamos tentar gerar seus embedding vectors.\n",
    "\n",
    "Palavras fora do vocabulário não são convertidas. Comumente artigos, números e outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "QgD5_4jLsCz9",
    "outputId": "c06b75af-bfbc-442e-e4de-0f06ec952c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens:  1944\n",
      "(1944, 50)\n",
      "Palavras convertidas: 1785 / não convertidas: 157)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "print(\"Número de tokens: \", num_tokens)\n",
    "embedding_dim = 50\n",
    "convertidas = 0\n",
    "falhas = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        if (embedding_vector.shape[0] != embedding_dim):\n",
    "          falhas += 1\n",
    "        else:\n",
    "          # Words not found in embedding index will be all-zeros.\n",
    "          # This includes the representation for \"padding\" and \"OOV\"\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "          convertidas += 1\n",
    "    else:\n",
    "        falhas += 1\n",
    "\n",
    "print(\"Palavras convertidas: %d / não convertidas: %d)\" % (convertidas, falhas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i7ACPhgLhEX"
   },
   "source": [
    "Montando a base de dados para o treinamento, no formato numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "aJ3zdvrs8hCJ",
    "outputId": "042181f3-9eca-4926-ec5a-15fd1766f517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 32)\n",
      "(46, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in x_val])).numpy()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB8_ADE9LkHC"
   },
   "source": [
    "## Camada de \"Word Embedding\"\n",
    "\n",
    "Para isso devemos informar o número de palavras, a dimensionalidade e passar a matrix com pesos pré-treinados.\n",
    "\n",
    "Caso não utilizemos os parâmetros `embeddings_initializer`, os pesos serão aleatórios.\n",
    "\n",
    "Também deixamos essa camada não treinável pois não queremos modificar as representações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WKNJE4NpHdu0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decaimento de learning rate\n",
    "def scheduler(epoch, lr):\n",
    "    if (epoch % 5 == 0): print(\"Época %04d - learning rate %.9f\" % (epoch, lr))\n",
    "    if (epoch+1 < 5):\n",
    "        return lr\n",
    "    else:\n",
    "        return np.round(lr * tf.math.exp(-0.005),9)\n",
    "\n",
    "callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3ClTHexL5j5"
   },
   "source": [
    "### Modelo baseado em Convoluções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "Vx6B7fRkr-yY",
    "outputId": "9e81f640-2993-4392-d1f7-6d20e5dbe60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 50)          97200     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 64)          6464      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 136,689\n",
      "Trainable params: 39,489\n",
      "Non-trainable params: 97,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(64, 2, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
    "x = layers.Conv1D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "modelConv = keras.Model(int_sequences_input, preds)\n",
    "modelConv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "id": "lYbD6f0eukTT",
    "outputId": "2e6a8df3-feaa-49dd-808d-67c7f55ccbfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Época 0000 - learning rate 0.001000000\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.7456 - acc: 0.4662 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6763 - acc: 0.5845 - val_loss: 0.6802 - val_acc: 0.5435\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6327 - acc: 0.6812 - val_loss: 0.6669 - val_acc: 0.6739\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5970 - acc: 0.7029 - val_loss: 0.6576 - val_acc: 0.6522\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5438 - acc: 0.7609 - val_loss: 0.6579 - val_acc: 0.6522\n",
      "Epoch 6/25\n",
      "Época 0005 - learning rate 0.000995013\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4692 - acc: 0.7657 - val_loss: 0.6720 - val_acc: 0.5870\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4378 - acc: 0.8213 - val_loss: 0.6631 - val_acc: 0.6522\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2793 - acc: 0.9179 - val_loss: 0.6332 - val_acc: 0.7391\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2181 - acc: 0.9517 - val_loss: 0.6983 - val_acc: 0.6739\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1683 - acc: 0.9662 - val_loss: 0.6540 - val_acc: 0.6087\n",
      "Epoch 11/25\n",
      "Época 0010 - learning rate 0.000970446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0998 - acc: 0.9879 - val_loss: 0.7021 - val_acc: 0.6739\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.9686 - val_loss: 0.7619 - val_acc: 0.6522\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0686 - acc: 0.9879 - val_loss: 0.7631 - val_acc: 0.6739\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - acc: 0.9976 - val_loss: 0.7850 - val_acc: 0.5435\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0300 - acc: 0.9976 - val_loss: 0.8101 - val_acc: 0.6739\n",
      "Epoch 16/25\n",
      "Época 0015 - learning rate 0.000946486\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0256 - acc: 0.9976 - val_loss: 0.8245 - val_acc: 0.6087\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8862 - val_acc: 0.5870\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.8953 - val_acc: 0.6087\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.6087\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.0635 - val_acc: 0.5870\n",
      "Epoch 21/25\n",
      "Época 0020 - learning rate 0.000923117\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9849 - val_acc: 0.6087\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.6304\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.9708 - val_acc: 0.6087\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9998 - val_acc: 0.5870\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.0031 - val_acc: 0.6087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a20703c40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelConv.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"acc\"]\n",
    ")\n",
    "modelConv.fit(x_train, y_train, batch_size=16, epochs=25, \n",
    "                  callbacks=[callbacklr], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzIdAcnKMDiz"
   },
   "source": [
    "Podemos agora testar frases novas!\n",
    "\n",
    "Para isso vou criar uma camada de entrada que passa por um vetorizador, e depois alimenta o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "iimkRQpgO5eS",
    "outputId": "cd231c40-b0fd-4355-bcd1-94efaa1e6470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
      "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  VERDADEIRO\n",
      "Acabou a corrupção no Brasil :  VERDADEIRO\n",
      "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = modelConv(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "frase = \"Na pós graduação, as mulheres são maioria\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Acabou a corrupção no Brasil\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utj_ygXrMLh2"
   },
   "source": [
    "### Modelo utilizando GRU\n",
    "\n",
    "Vamos substituir uma camada convolucional por uma GRU (poderia ser uma LSTM também)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cLvDalHe6Ol7",
    "outputId": "82c09324-032d-4864-9ddc-af5d0b381cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 50)          97200     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 64)          6464      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                24960     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 132,849\n",
      "Trainable params: 35,649\n",
      "Non-trainable params: 97,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(64, 2, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predsGRUout = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "modelGRU = keras.Model(inputs=int_sequences_input, outputs=predsGRUout)\n",
    "modelGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "id": "BpqJfZgX6poK",
    "outputId": "0db1fa4b-26e9-4524-e67a-e6618141c98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Época 0000 - learning rate 0.001000000\n",
      "26/26 [==============================] - 2s 15ms/step - loss: 0.6929 - acc: 0.4952 - val_loss: 0.7073 - val_acc: 0.5435\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6861 - acc: 0.4952 - val_loss: 0.6992 - val_acc: 0.4348\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6832 - acc: 0.5217 - val_loss: 0.7058 - val_acc: 0.5435\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6735 - acc: 0.5217 - val_loss: 0.7049 - val_acc: 0.4348\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6712 - acc: 0.5242 - val_loss: 0.7069 - val_acc: 0.4783\n",
      "Epoch 6/25\n",
      "Época 0005 - learning rate 0.000995013\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6658 - acc: 0.5386 - val_loss: 0.7039 - val_acc: 0.4565\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - acc: 0.5556 - val_loss: 0.7103 - val_acc: 0.3913\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6474 - acc: 0.5435 - val_loss: 0.6933 - val_acc: 0.5435\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6336 - acc: 0.5966 - val_loss: 0.7432 - val_acc: 0.3696\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6296 - acc: 0.6256 - val_loss: 0.7570 - val_acc: 0.5435\n",
      "Epoch 11/25\n",
      "Época 0010 - learning rate 0.000970446\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6222 - acc: 0.5821 - val_loss: 0.6871 - val_acc: 0.4783\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5964 - acc: 0.6329 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5783 - acc: 0.6836 - val_loss: 0.6800 - val_acc: 0.4783\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5542 - acc: 0.7029 - val_loss: 0.6167 - val_acc: 0.6739\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5554 - acc: 0.7126 - val_loss: 0.6356 - val_acc: 0.6087\n",
      "Epoch 16/25\n",
      "Época 0015 - learning rate 0.000946486\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5894 - acc: 0.7005 - val_loss: 0.6473 - val_acc: 0.6304\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5097 - acc: 0.7729 - val_loss: 0.7038 - val_acc: 0.6304\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5518 - acc: 0.7077 - val_loss: 0.6048 - val_acc: 0.6739\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4976 - acc: 0.7657 - val_loss: 0.6138 - val_acc: 0.5652\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4643 - acc: 0.7536 - val_loss: 0.9709 - val_acc: 0.5870\n",
      "Epoch 21/25\n",
      "Época 0020 - learning rate 0.000923117\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4014 - acc: 0.8213 - val_loss: 0.5628 - val_acc: 0.7826\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3446 - acc: 0.8599 - val_loss: 0.6693 - val_acc: 0.6957\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2944 - acc: 0.8816 - val_loss: 0.6348 - val_acc: 0.7174\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2648 - acc: 0.8889 - val_loss: 0.5510 - val_acc: 0.7391\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2074 - acc: 0.9300 - val_loss: 0.8632 - val_acc: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a7c304130>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelGRU.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"acc\"]\n",
    ")\n",
    "modelGRU.fit(x_train, y_train, batch_size=16, epochs=25, \n",
    "                  callbacks=[callbacklr], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "qiLfD7Ln643M",
    "outputId": "f84c2e2e-f6ae-4a43-d60c-b90d87f95aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
      "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  FALSO\n",
      "Acabou a corrupção no Brasil :  FALSO\n",
      "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "predsGRU = modelGRU(x)\n",
    "end_to_end_modelGRU = keras.Model(string_input, predsGRU)\n",
    "\n",
    "frase = \"Na pós graduação, as mulheres são maioria\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Acabou a corrupção no Brasil\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-06-Aula-notebook2_wordembedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
