{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvaEK6Bn-wwG"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo 7 - Introdução ao Aprendizado por Reforço</span>\n",
    "\n",
    "#### <span style=\"color:darkred\">**Parte 1: Biblioteca Gym e Problemas Benchmark de Aprendizado por Reforço**</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "A biblioteca `gym` foi criada pela OpenAI com o objetivo de avaliar algoritmos de aprendizado por reforço.\n",
    "\n",
    "Ela contem vários ambientes modelados nesse paradigma que podem servir para entender melhor como funciona esse tipo de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema \"Montain Car\"\n",
    "\n",
    "Versão discreta\n",
    "\n",
    "**Observação**:<br>\n",
    "0 : Posição: [-1.2, 0.6]<br>\n",
    "1 : Velocidade: [-0.07, 0.07]\n",
    "\n",
    "**Ações**:<br>\n",
    "0 : Acelerar para Esquerda<br>\n",
    "1 : Não acelerar<br>\n",
    "2 : Acelerar para Direita\n",
    "\n",
    "**Recompensas**:<br>\n",
    "* 0 : se o agente atingir a bandeira (posição 0.5)<br>\n",
    "* -1 : se a posição do agente é menor que 0.5\n",
    "\n",
    "**Término**:\n",
    "* Tamanho do episódio maior do que 200 - no máximo 200 ações\n",
    "* Posição do carro maior ou igual a 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posicao, velocidade:  [-0.56446785  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# inicializacao e estado inicial\n",
    "observ0 = env.reset()\n",
    "print(\"Posicao, velocidade: \", observ0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultima Acao:  0\n",
      "Posicao, velocidade finais:  [-0.4268427   0.00106375]\n",
      "Episódio finalizou após 0 passos\n"
     ]
    }
   ],
   "source": [
    "for t in range(301):\n",
    "    # exibe estado atual\n",
    "    env.render()\n",
    "    \n",
    "    # obtem acao aleatoriamente\n",
    "    acao = env.action_space.sample()\n",
    "    \n",
    "    # executa acao e obtem observacao/recompensa\n",
    "        #fim=True chegou no estado terminal\n",
    "        #rec=recompensa\n",
    "        #obs=observação\n",
    "    obs, rec, fim, info = env.step(acao)\n",
    "    \n",
    "    if (t % 50 == 1):\n",
    "        print(\"%d, Acao: %d, Rec: %d, Obs: %.2f, %.2f\" % (t, acao, rec, obs[0], obs[1]))\n",
    "    \n",
    "    if fim:\n",
    "        print(\"Ultima Acao: \", acao)\n",
    "        print(\"Posicao, velocidade finais: \", obs)\n",
    "        print(\"Episódio finalizou após %d passos\" % (t))\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há uma versão contínua cujo espaço de ações é [-1, 1]\n",
    "\n",
    "-1 : Aceleração total para a esquerda<br>\n",
    "0 : Não acelerar<br>\n",
    "1 : Aceleração total para a direita\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-1.], [1.], (1,), float32)\n",
      "Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultima Acao:  [0.05590169]\n",
      "Posicao, velocidade finais:  [-0.643667   0.0075392]\n",
      "Episódio finalizou após 999 passos\n"
     ]
    }
   ],
   "source": [
    "# inicializacao e estado inicial\n",
    "observ0 = env.reset()\n",
    "\n",
    "n_acoes = 1000\n",
    "\n",
    "# acoes\n",
    "for t in range(1,n_acoes+1):\n",
    "    # exibe estado atual\n",
    "    env.render()\n",
    "    \n",
    "    # obtem acao aleatoriamente\n",
    "    acao = env.action_space.sample()\n",
    "    \n",
    "    # executa acao e obtem observacao/recompensa\n",
    "    obs, rec, fim, info = env.step(acao)\n",
    "    \n",
    "    if (fim or t == n_acoes):\n",
    "        print(\"Ultima Acao: \", acao)\n",
    "        print(\"Posicao, velocidade finais: \", obs)\n",
    "        print(\"Episódio finalizou após %d passos\" % (t))\n",
    "        break    \n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Outros ambientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v1), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v1), EnvSpec(FrozenLake-v1), EnvSpec(FrozenLake8x8-v1), EnvSpec(CliffWalking-v0), EnvSpec(Taxi-v3), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])\n"
     ]
    }
   ],
   "source": [
    "from gym import envs\n",
    "print(envs.registry.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(6)\n",
      "Discrete(500)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problema do Taxi\n",
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problema do táxi\n",
    "\n",
    "* Temos 4 localizações relevantes indicadas por 0:R, 1:G, 2:Y e 3:B.\n",
    "* Azul é o passageiro e magenta o destino.\n",
    "* O taxi é amarelo quando livre e verde quando ocupado\n",
    "* Grid contém 25 posições para o táxi, 5 para o passageiro, e 4 destinos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Ações**:<br>\n",
    "0 : mover para norte<br>\n",
    "1 : mover para sul<br>\n",
    "2 : mover para leste<br>\n",
    "3 : mover para oeste<br>\n",
    "4 : pegar passageiro (pickup)<br>\n",
    "5 : deixar passageiro (dropoff)\n",
    "\n",
    "**Observação/estado**:<br>\n",
    "Posições do taxi, passageiro e destino codificada numericamente\n",
    "\n",
    "**Recompensas**:<br>\n",
    "* -1 : por passo<br>\n",
    "* 20 : deixar passageiro<br>\n",
    "* -10: executar \"pegar\" ou \"deixar\" ilegalmente\n",
    "\n",
    "**Término**:\n",
    "* Passageiro é deixado no destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado inicial:  49 \n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Estado atual: 149\n",
      "Recompensa:  -1\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Estado atual: 149\n",
      "Recompensa:  -10\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Estado atual: 149\n",
      "Recompensa:  -10\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Estado atual: 249\n",
      "Recompensa:  -1\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Estado atual: 349\n",
      "Recompensa:  -1\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Estado atual: 349\n",
      "Recompensa:  -10\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Estado atual: 349\n",
      "Recompensa:  -10\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Estado atual: 349\n",
      "Recompensa:  -10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicializacao e estado inicial\n",
    "observ0 = env.reset()\n",
    "print(\"Estado inicial: \", observ0, \"\\n\")\n",
    "for t in range(8):\n",
    "    acao = env.action_space.sample()\n",
    "    s, r, fim, info = env.step(acao) # take a random action\n",
    "    \n",
    "    env.render()\n",
    "    print(\"Estado atual:\", s)\n",
    "    print(\"Recompensa: \", r)\n",
    "    print()\n",
    "\n",
    "    if fim:\n",
    "        print(\"Episódio finalizou após %d passos\" % (t))\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def animacao_episodio(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(\"t: \", (i + 1))\n",
    "        print(\"State: \", frame['state'])\n",
    "        print(\"Action: \", frame['action'])\n",
    "        print(\"Reward: \", frame['reward'])\n",
    "        sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "\n",
      "t:  100\n",
      "State:  226\n",
      "Action:  3\n",
      "Reward:  -1\n",
      "Recompensa total episódio:  -334\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "# inicializacao e estado inicial\n",
    "observ0 = env.reset()\n",
    "\n",
    "frames = [] # animacao\n",
    "\n",
    "rec_total = 0\n",
    "\n",
    "# passos\n",
    "for t in range(100):\n",
    "    \n",
    "    # amostra ação do espaço\n",
    "    a = env.action_space.sample()\n",
    "    # executa acao\n",
    "    s, r, fim, info = env.step(a) \n",
    "    \n",
    "    rec_total += r\n",
    "    \n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': s,\n",
    "        'action': a,\n",
    "        'reward': r\n",
    "        }\n",
    "    )\n",
    "        \n",
    "    if fim:\n",
    "        print(\"Episódio finalizou após %d passos\" % (t))\n",
    "        break\n",
    "    \n",
    "env.close()\n",
    "\n",
    "animacao_episodio(frames)\n",
    "print(\"Recompensa total episódio: \", rec_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-06-Aula-notebook1_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
