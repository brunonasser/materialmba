{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo V - Redes neurais auto-associativas e geradoras</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle, use esse notebook apenas para gerar o código necessário para obter as respostas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "### Questão 1)\n",
    "\n",
    "Qual a diferença entre um Autoencoder convencional (AE) e um Variational Autoencoder (VAE)?\n",
    "\n",
    "(a) VAE aprende uma representação latente com base na comparação entre exemplos reais e exemplos gerados artificialmente, enquanto que o AE aprende apenas a partir de dados reais<br>\n",
    "(b) O espaço latente do VAE é composto por parâmetros de distribuições a partir dos quais são amostrados o exemplos a serem decodificados pelo elemento decoder, enquanto que o espaço latente do AE é aprendido sem assumir distribuições para suas dimensões.<br>\n",
    "(c) O espaço latente do AE é composto por parâmetros de distribuições a partir dos quais são amostrados o exemplos a serem decodificados pelo elemento decoder, enquanto que o espaço latente do VAE é aprendido sem assumir distribuições para suas dimensões, permitindo que esse seja usado também como modelo gerador.<br>\n",
    "(d) VAE aprende apenas a partir de dados reais, enquanto o AE aprende com base na comparação entre exemplos reais na entrada e exemplos gerados artificialmente em sua saída<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questão 2)\n",
    "\n",
    "\n",
    "Considere os métodos Generative Adversarial Networks, Denoising Autoencoder e Variational Autoencoder. Podemos dizer que esses métodos se enquadram em qual tipo de paradigma aprendizado?\n",
    "\n",
    " (a) Supervisionado<br>\n",
    " (b) Semi-supervisionado<br>\n",
    " (c) Não supervisionado<br>\n",
    " (d) Fracamente supervisionado<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "O objetivo principal no aprendizado de uma rede do tipo Generative Adversarial Network é\n",
    "\n",
    " (a) Aprender as operações que permitem, a partir de um exemplo aleatório amostrado de uma determinada distribuição, gerar um exemplo que se assemelhe a uma amostra obtida da distribuição dos dados de treinamento<br>\n",
    " (b) Classificar exemplos fornecidos para a rede neural em exemplos advindos do conjunto de treinamento da base de dados de interesse, e exemplos que não pertençam a esse conjunto.<br>\n",
    " (c) Realizar uma regressão da distribuição de entrada para um espaço latente compacto e de menor dimensionalidade que a entrada, a partir do qual podemos reconstruir um exemplo de forma fiel com relação à sua dimensionalidade original<br>\n",
    " (d) Obter um modelo que aprenda a distribuição dos dados de entrada e que projete esses dados num espaço que seja robusto a possíveis ruídos em dados futuros, permitindo assim evitar ataques adversariais.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Carregue a base de dados `wine.csv`, conforme abaixo, com uma divisão hold-out utilizando os 80% exemplos iniciais para treinamento e os restantes para teste. Utilizaremos normalização min-max 0-1. Utilizaremos apenas os exemplos de treinamento obtidos nessa separação.\n",
    "\n",
    "Projete um Autoencoder para produzir um espaço de características com 5 dimensões, com as seguintes camadas:\n",
    "* Entrada (com as dimensões da base de dados)\n",
    "* Dropout de 0.25\n",
    "* Camada densa de 5 neurônios (camada de código) e ativação relu\n",
    "* Camada densa de saída (com as dimensões da base de dados) e ativação sigmoide\n",
    "\n",
    "Código é o nome que se dá à camada latente do Autoencoder, geralmente aquela contendo a maior restrição de dimensionalidade, que fornece um espaço de características compacto para os dados de entrada. Também chamamos de código as características obtidas a partir dessa camada.\n",
    "\n",
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar.\n",
    "\n",
    "Utilize a função de custo mean absolute error (mse), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas.\n",
    "\n",
    "Após o treinamento, obtenha as características a partir da camada \"código\" do Autoencoder e grafe um scatterplot das duas primeiras características do código de treinamento, analisando visualmente a distribuição desses dados com relação das classes. Podemos identificar qual distribuição dos dados em termos da separação e sobreposição de classes?\n",
    "\n",
    "(a) classe mais distintamente separada: 1, classes sobrepostas: 0 e 2<br>\n",
    "(b) classe mais distintamente separada: 0, classes sobrepostas: 1 e 2 <br>\n",
    "(c) classes mais distintamente separadas: 0, 1 e 2, classes sobrepostas: nenhuma<br>\n",
    "(d) classe mais distintamente separada: 2, classes sobrepostas: 0 e 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rif40G6wST-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine.csv\")\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())\n",
    "classif = np.array(df['Class'].astype(\"category\").cat.codes)\n",
    "features = np.array(df.iloc[:, :-1])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classif, test_size=0.20, random_state=0)\n",
    "print(\"Exemplos de treinamento:\", len(X_train))\n",
    "print(\"Exemplos de teste:\", len(X_test))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_n = scaler.fit_transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### projetar autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir sementes, instanciar AE, compilar e treinar\n",
    "epochs = 300\n",
    "batch_size = 10\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "# instanciar AE\n",
    "# compilar AE\n",
    "# treinar AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obter características dos dados de treinamento a partir da camada de código do autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exibir as duas primeiras caracerísticas para análise visual\n",
    "size_sample = len(X_train)\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(code_train[:size_sample,0], code_train[:size_sample,1], c=y_train[:size_sample], alpha=0.75, cmap=\"jet\")\n",
    "legend1 = ax.legend(*scatter.legend_elements(), loc=\"lower right\", title=\"Classes\")\n",
    "ax.add_artist(legend1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "\n",
    "Carregue a base de dados `wine.csv`, conforme abaixo, com uma divisão hold-out utilizando os 80% exemplos iniciais para treinamento e os restantes para teste. \n",
    "\n",
    "Projete um Autoencoder profundo para produzir uma projeção em 3 dimensões, com as seguintes camadas:\n",
    "* Entrada (com as dimensões originais da base de dados)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa com 3 neurônios (camada de código), ativação relu\n",
    "* Dropout de 1/3.0 (um terço)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa de saída (com as dimensões originais da base de dados), ativação sigmóide\n",
    "\n",
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar (com o conjunto de treinamento).\n",
    "\n",
    "Utilize a função de custo mean squared error (MSE), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas.\n",
    "\n",
    "Após o treinamento:\n",
    "1. Calcule o MSE (do autoencoder) no conjunto de teste\n",
    "2. Obtenha as características a partir do código de 3 dimensões para o conjunto de treinamento e de teste. Treine um classificador SVM (utilizando `SVC(C=0.5, random_state=1, kernel=\"rbf\")`) com o código de treinamento (3 dimensões). Calcule a acurácia obtida pelo SVM no conjunto de teste (utilizando as características obtidas a partir do autoencoder).\n",
    "\n",
    "Os valores observados de MSE no teste do autoencoder, e acurácia de classificação SVM no teste estão em qual intervalo?\n",
    "\n",
    "(a) MSE =[0.01, 0.08]; Acurácia = [0.73, 0.82] <br>\n",
    "(b) MSE =[0.01, 0.08]; Acurácia = [0.87, 0.98] <br>\n",
    "(c) MSE =[0.10, 0.16]; Acurácia = [0.73, 0.82] <br>\n",
    "(d) MSE =[0.10, 0.16]; Acurácia = [0.87, 0.98] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classif, test_size=0.20, random_state=0)\n",
    "print(\"Exemplos de treinamento:\", len(X_train))\n",
    "print(\"Exemplos de teste:\", len(X_test))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_n = scaler.fit_transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
