{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNAPADPMPProvaFinal.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"flekT6GFDN6m"},"source":["#PREENCHA SEU NOME COMPLETO AQUI: \n","\n","### <span style=\"color:blue\">MBA em Ciência de Dados</span>\n","### <span style=\"color:blue\">Redes Neurais e Arquiteturas Profundas</span>\n","### <span style=\"color:blue\">Análise de Dados com Base em Processamento Massivo em Paralelo</span>\n","\n","### <span style=\"color:blue\">Prova Final</span>\n","\n","**Material Produzido por:**<br>\n",">**Profa. Dra. Cristina Dutra de Aguiar**<br>\n",">**Prof. Dr. Moacir A. Ponti**<br> \n","\n","**CEMEAI - ICMC/USP São Carlos**\n","\n","\n","A prova final contém 1 questão, dividida em 3 itens. Por favor, procurem por Questão para encontrar a especificação da questão e por RESOLVER para encontrar a especificação do item a ser solucionado. Também é possível localizar a questão e os itens utilizando o menu de navegação. \n","\n","O notebook contém a constelação de fatos da BI Solutions que deve ser utilizada para responder à questão e também todas as `bibliotecas`, `bases de dados`, `inicializações`, `instalações`, `importações`, `geração de dataFrames`, `geração de visões temporárias` e `conversão dos tipos de dados` necessárias para a realização da questão.\n","\n","\n","**INSTRUÇÕES**:<br>\n","1) Você deve exportar esse notebook com sua solução para as questões da prova em formato .py e fazer upload no Moodle. Atenção: você não deve fazer upload de um arquivo notebook (.ipynb), mas sim um arquivo texto .py contendo os códigos python que utilizou para resolver as questões. O arquivo .py pode ser gerado através da opção:<br>\n","File --> Download as --> Python (.py)\n","disponível no Jupyter Notebook.\n","\n","ou\n","File --> Download .py\n","no Google Colab\n","\n","Caso não esteja utilizando o Jupyter, copie e cole seu código em um arquivo ASCII (Texto) salvando com a extensão .py\n","\n","2) Você deve salvar esse notebook com sua solução para as questões da prova em formato .pdf e fazer upload no Moodle\n","\n","3) Os arquivos devem ser nomeados com seu nome e sobrenome, sem espaços. Exemplo: moacirponti.py e moacirponti.pdf\n","\n","4) É OBRIGATÓRIO conter no cabeçalho (início) do arquivo um comentário / texto com o seu nome completo\n","\n","\n","**Desejamos uma boa prova!**"]},{"cell_type":"markdown","metadata":{"id":"3o3dN_WLQcyD"},"source":["#1 Constelação de Fatos da BI Solutions\n","\n","A aplicação de *data warehousing* da BI Solutions utiliza como base uma contelação de fatos, conforme descrita a seguir.\n","\n","**Tabelas de dimensão**\n","\n","- data (dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno)\n","- funcionario (funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla)\n","- equipe (equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla)\n","- cargo (cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel)\n","- cliente (clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla)\n","\n","**Tabelas de fatos**\n","- pagamento (dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamentos)\n","- negociacao (dataPK, equipePK, clientePK, receita, quantidadeNegociacoes)\n"]},{"cell_type":"markdown","metadata":{"id":"BGeh8KdXwVCQ"},"source":["#2 Configurações \n"]},{"cell_type":"markdown","metadata":{"id":"lWX2HVtNSw8w"},"source":["## 2.1 Obtenção dos Dados da BI Solutions"]},{"cell_type":"code","metadata":{"id":"3e0Eao1K0EYG"},"source":["#instalando o módulo wget\n","%%capture\n","!pip install -q wget\n","!mkdir data\n","\n","#baixando os dados das tabelas de dimensão e das tabelas de fatos\n","import wget\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/data.csv\"\n","wget.download(url, \"data/data.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/funcionario.csv\"\n","wget.download(url, \"data/funcionario.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/equipe.csv\"\n","wget.download(url, \"data/equipe.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/cargo.csv\"\n","wget.download(url, \"data/cargo.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/cliente.csv\"\n","wget.download(url, \"data/cliente.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/pagamento.csv\"\n","wget.download(url, \"data/pagamento.csv\")\n","\n","url = \"https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/negociacao.csv\"\n","wget.download(url, \"data/negociacao.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sO16-7-jOioq"},"source":["## 2.2 Instalações e Inicializações"]},{"cell_type":"code","metadata":{"id":"gFfZ3QoxuV6q"},"source":["#instalando Java Runtime Environment (JRE) versão 8\n","%%capture\n","!apt-get remove openjdk*\n","!apt-get update --fix-missing\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpSR-ffXuZS3"},"source":["#baixando Apache Spark versão 3.0.0\n","%%capture\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XC4whsGcuiEF"},"source":["import os\n","#configurando a variável de ambiente JAVA_HOME\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","#configurando a variável de ambiente SPARK_HOME\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMmfchBEuky0"},"source":["%%capture\n","#instalando o pacote findspark\n","!pip install -q findspark==1.4.2\n","#instalando o pacote pyspark\n","!pip install -q pyspark==3.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_8fiSPVwqAO"},"source":["## 2.3 Bibliotecas"]},{"cell_type":"code","metadata":{"id":"NXls3bfoglKW"},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()\n","\n","from pyspark.sql.types import IntegerType\n","from pyspark.sql.types import FloatType\n","from pyspark.sql.functions import round, desc\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from numpy.random import seed\n","from tensorflow.random import set_seed\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4 Geração dos DataFrames em Pandas da BI Solutions\n","\n","Nesta seção são gerados os DataFrames em Pandas. Atenção aos nomes desses DataFrames. "],"metadata":{"id":"OcSO2MjXC23E"}},{"cell_type":"code","source":["pd.set_option('display.float_format', lambda x: '%.2f' % x)"],"metadata":{"id":"6a0nRg8NC83e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cargoPandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/cargo.csv')\n","clientePandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/cliente.csv')\n","dataPandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/data.csv')\n","equipePandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/equipe.csv')\n","funcionarioPandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/funcionario.csv')\n","negociacaoPandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/negociacao.csv')\n","pagamentoPandas = pd.read_csv('https://raw.githubusercontent.com/cdaciferri/DataMartBISolutions/main/pagamento.csv')"],"metadata":{"id":"CyQlExKoDBrb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5qL9SiR_pQE2"},"source":["## 2.5 Geração dos DataFrames em Spark da BI Solutions\n","\n","Nesta seção são gerados dos DataFrames em Spark. Atenção aos nomes desses DataFrames. "]},{"cell_type":"code","metadata":{"cellView":"both","id":"FNR-3dV6oYk4"},"source":["#criando os DataFrames em Spark \n","cargo = spark.read.csv(path=\"data/cargo.csv\", header=True, sep=\",\")\n","cliente = spark.read.csv(path=\"data/cliente.csv\", header=True, sep=\",\")\n","data = spark.read.csv(path=\"data/data.csv\", header=True, sep=\",\")\n","equipe = spark.read.csv(path=\"data/equipe.csv\", header=True, sep=\",\")\n","funcionario = spark.read.csv(path=\"data/funcionario.csv\", header=True, sep=\",\")\n","negociacao = spark.read.csv(path=\"data/negociacao.csv\", header=True, sep=\",\")\n","pagamento = spark.read.csv(path=\"data/pagamento.csv\", header=True, sep=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmCV6Mur__z6"},"source":["#convertendo os dados necessários para o tipo de dado inteiro\n","colunas_cargo = [\"cargoPK\"]\n","colunas_cliente = [\"clientePK\"]\n","colunas_data = [\"dataPK\", \"dataDia\", \"dataMes\", \"dataBimestre\", \"dataTrimestre\", \"dataSemestre\", \"dataAno\"]\n","colunas_equipe = [\"equipePK\"]\n","colunas_funcionario = [\"funcPK\", \"funcDiaNascimento\", \"funcMesNascimento\", \"funcAnoNascimento\"]\n","colunas_negociacao = [\"equipePK\", \"clientePK\", \"dataPK\", \"quantidadeNegociacoes\"]\n","colunas_pagamento = [\"funcPK\", \"equipePK\", \"dataPK\", \"cargoPK\", \"quantidadeLancamentos\"]\n","\n","for coluna in colunas_cargo:\n","  cargo = cargo.withColumn(coluna, cargo[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_cliente:\n","  cliente = cliente.withColumn(coluna, cliente[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_data:\n","  data = data.withColumn(coluna, data[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_equipe:\n","  equipe = equipe.withColumn(coluna, equipe[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_funcionario:\n","  funcionario = funcionario.withColumn(coluna, funcionario[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_negociacao:\n","  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(IntegerType()))\n","\n","for coluna in colunas_pagamento:\n","  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(IntegerType()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBcQ7Ep7AWqN"},"source":["#convertendo os dados necessários para o tipo de dado float\n","colunas_negociacao = [\"receita\"]\n","colunas_pagamento = [\"salario\"]\n","\n","for coluna in colunas_negociacao:\n","  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(FloatType()))\n","\n","for coluna in colunas_pagamento:\n","  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(FloatType()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJsqRI3TwsjS"},"source":["#criando as visões temporárias \n","cargo.createOrReplaceTempView(\"cargo\")\n","cliente.createOrReplaceTempView(\"cliente\")\n","data.createOrReplaceTempView(\"data\")\n","equipe.createOrReplaceTempView(\"equipe\")\n","funcionario.createOrReplaceTempView(\"funcionario\")\n","negociacao.createOrReplaceTempView(\"negociacao\")\n","pagamento.createOrReplaceTempView(\"pagamento\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 Questão\n","\n","A empresa BI Solutions está realizando uma investigação baseada no projeto e treinamento de uma rede neural, usando como base seus dados históricos mantidos na Constelação de Fatos. O modelo resultante deve ser usado para obter uma predição, a qual é voltada à análise da investigação esperada.\n","\n","**IMPORTANTE**: Leia a questão com muita atenção, desde que vários passos da questão já se encontram implementados. Os locais nos quais os comandos de resposta para os itens da questão devem ser especificados são identificados em comentários. "],"metadata":{"id":"HT3nHMvLEjJM"}},{"cell_type":"markdown","source":["## 3.1 Investigação dos Dados Históricos\n","\n","A primeira parte para solucionar a investigação consiste na obtenção de dados históricos de interesse. Isso deve feito por meio da especificação de uma consulta OLAP, segundo as instruções detalhadas a seguir."],"metadata":{"id":"MzJ9rpC-FEbk"}},{"cell_type":"markdown","source":["### 3.1.1 Instruções para a Especificação da Consulta OLAP"],"metadata":{"id":"ojucED8vG566"}},{"cell_type":"markdown","source":["\n","- A **consulta OLAP** pode ser especificada usando qualquer uma das três opções a seguir (escolha SOMENTE UMA forma)\n","   - Usando **Pandas** (conceitos apresentados na Aula 05). \n","   - Usando a **linguagem SQL** (conceitos apresentados na Aula 07). \n","   - Usando os métodos de **pyspark.sql** (conceitos apresentados na Aula 08). \n","- Na listagem das respostas:\n","   - As **colunas** solicitadas devem ser exibidas exatamente na mesma ordem que a definida.\n","   - As **linhas** retornadas como respostas devem ser exibidas exatamente na mesma ordem que a definida. \n","   - Os **nomes das colunas** renomeadas devem seguir estritamente os nomes definidos.\n"],"metadata":{"id":"Ha-KIoABFXou"}},{"cell_type":"markdown","source":["### 3.1.2 Consulta OLAP (RESOLVER)\n","\n","Liste, para cada código da equipe, setor do cliente e nome do estado do cliente, a soma das receitas. Arredonde a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"CODIGOEQUIPE\", \"SETORCLIENTE\", \"NOMEESTADOCLIENTE\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro pelo total de receita em ordem ascendente, depois pelo código da equipe em ordem ascendente, depois pelo setor do cliente em ordem ascendente, depois pelo nome do estado em ordem ascendente. "],"metadata":{"id":"RDa1gJ0eHHFN"}},{"cell_type":"code","source":["# Escreva aqui a sua resposta para a consulta OLAP"],"metadata":{"id":"fpJCndPHIp4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Caso tenha feito a sua resposta usando a linguagem SQL\n","# querySQL = \"\"\" comando SQL \"\"\"\n","# Transforme o resultado da consulta, o qual encontra-se em \"querySQL\", \n","# em um dataFrame em Pandas descomentando o comando a seguir: \n","\n","# df = spark.sql(querySQL).toPandas()"],"metadata":{"id":"xsnleUDfJWBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Caso tenha feito a sua resposta usando os métodos de pyspark.sql\n","# dataFramepyspark = resposta em pyspark sem finalizar com o método .show()\n","# Transforme o resultado da consulta, o qual encontra-se \n","# em \"dataFramepyspark\", em um dataFrame em Pandas\n","# descomentando o comando a seguir: \n","\n","# df = dataFramepyspark.toPandas()"],"metadata":{"id":"SWfmw6fCV7FH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Em qualquer caso, exiba algumas linhas do dataFrame de nome df,\n","# o qual é um dataFrame em Pandas, descomentando o comando a seguir:\n","\n","# df"],"metadata":{"id":"0t5cKRDmKD_z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note que o dataFrame em Pandas, chamado `df`, é o dataFrame a ser utilizado para o treinamento da rede neural. "],"metadata":{"id":"yZuciwUkY7bc"}},{"cell_type":"markdown","source":["## 3.2 Treinamento da Rede Neural\n","\n","A segunda parte para solucionar a investigação consiste no treinamento da rede neural usando como base os dados históricos obtidos no item 3.1.2, segundo as instruções detalhadas a seguir. \n"],"metadata":{"id":"vJZoVGt5RdHF"}},{"cell_type":"markdown","source":["### 3.2.1 Preparação dos Dados\n","\n","A preparação dos dados já encontra-se pronta, sendo necessário apenas executar as células."],"metadata":{"id":"lxEPbn7V76NS"}},{"cell_type":"code","source":["# ordena dados\n","df = df.sort_values(by='CODIGOEQUIPE')\n","\n","# obtem dummy-variables / one-hot-encoding\n","setor = pd.get_dummies(df['SETORCLIENTE'])\n","estado = pd.get_dummies(df['NOMEESTADOCLIENTE'])\n","equipe = pd.get_dummies(df['CODIGOEQUIPE'])\n","\n","# cria dataframe para treinamento\n","input_data = pd.concat([equipe, setor, estado, df['TOTALRECEITA']], axis=1, sort=False)"],"metadata":{"id":"_Jcs2DhLRglc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# separa dados de treinamento e 1 para teste\n","n_test = 1\n","\n","x_train = np.array(input_data.iloc[:-n_test,:-1])\n","x_test = np.array(input_data.iloc[-n_test:,:-1])\n","\n","y_train = np.array(input_data.iloc[:-n_test,-1])\n","y_test = np.array(input_data.iloc[-n_test,-1])\n","\n","print(\"Tamanho conjunto de treinamento: \", x_train.shape)\n","print(\"Tamanho conjunto de testes: \", x_test.shape)"],"metadata":{"id":"lT-6ZQa8R0i6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# valor maximo para normalizar receita\n","y_max = np.max(y_train)\n","print('Max train', y_max)"],"metadata":{"id":"anhOw7rVXBO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dados para regressao normalizados\n","y_train = np.array(input_data.iloc[:-n_test,-1])/y_max\n","y_test = np.array(input_data.iloc[-n_test:,-1])/y_max"],"metadata":{"id":"x_hfwscQV_D0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2.2 Projeto e Treinamento de Rede Neural (RESOLVER)\n","\n","Utilize o código a seguir e, em seguida, compile e treine a rede neural utilizando: \n","* função de custo de erro médio quadrático,\n","* learning rate inicial de 0.005 e decaimento dado pela função `scheduler` provida, \n","* 30 épocas, \n","* batchsize de tamanho 10."],"metadata":{"id":"24qa-1w6WBJL"}},{"cell_type":"code","source":["def deep_net(neurons, input_dim, n_layers=1, batch_norm=False, dropout_rate=0.0):\n","    \n","    input_data = keras.layers.Input(shape=(input_dim,))\n","    \n","    x = keras.layers.Activation('relu')(input_data)\n","    if batch_norm: \n","        x = keras.layers.BatchNormalization(name='bn_input')(x)\n","        x = keras.layers.Activation('relu')(x)\n","    x = keras.layers.Dense(neurons, activation='relu')(x)\n","    x = keras.layers.Dense(neurons, activation='relu')(x)\n","    x = keras.layers.Dropout(dropout_rate)(x)\n","    output = keras.layers.Dense(1, activation='relu')(x)\n","    dnn = keras.models.Model(input_data, output)\n","    \n","    return dnn"],"metadata":{"id":"C9mr4beoWBTq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scheduler(epoch, lr):\n","    if epoch < 5: return lr\n","    return lr * tf.math.exp(-0.05)\n","\n","callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)"],"metadata":{"id":"KyhrmJ_EWbOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed(1)\n","set_seed(2)\n","dnn = deep_net(64, x_train.shape[1], batch_norm=False, dropout_rate=0.5)"],"metadata":{"id":"hebOn8M1WuAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Escreva aqui a sua resposta para a compilação e treinamento de rede neural\n","\n","# compilar\n","# treinar"],"metadata":{"id":"lEeK3wK3qdbZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2.3 Predição da receita (RESOLVER)\n","\n","Utilizando o modelo treinado, realize a predição da receita para a linha separada para teste, i.e. a linha em `x_test`\n","\n","Não se esqueça de, após obter a predição, reescalar novamente para o intervalo original dos dados, revertendo a normalização feita na etapa de preparação dos dados."],"metadata":{"id":"l-opAGs0Wke7"}},{"cell_type":"code","source":["# Escreva aqui a sua resposta para a predição de receita em milhões de reais"],"metadata":{"id":"Z1qaUYxer3Vb"},"execution_count":null,"outputs":[]}]}