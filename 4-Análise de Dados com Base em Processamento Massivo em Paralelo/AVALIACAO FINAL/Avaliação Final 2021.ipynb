{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação Final 2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flekT6GFDN6m"
      },
      "source": [
        "# <span style=\"color:blue\">MBA em Ciência de Dados</span>\n",
        "# <span style=\"color:blue\">Análise de Dados com Base em Processamento Massivo em Paralelo</span>\n",
        "\n",
        "## <span style=\"color:blue\">Avaliação Final</span>\n",
        "\n",
        "**Material Produzido por:**<br>\n",
        ">**Profa. Dra. Cristina Dutra de Aguiar**<br>\n",
        "\n",
        "\n",
        "**CEMEAI - ICMC/USP São Carlos**\n",
        "\n",
        "As questões desta avaliação final estão espalhadas ao longo do texto. Por favor, procurem por Questão para encontrar a especificação das questões e o local no qual cada questão deve ser respondida. Também é possível localizar as questões utilizando o menu de navegação. O *notebook* contém a constelação de fatos da BI Solutions que deve ser utilizada para responder às questões e também todas as bibliotecas, bases de dados, inicializações, instalações, importações, geração de dataFrames, geração de visões temporárias e conversão dos tipos de dados necessárias para a realização da questão. Portanto, o notebook está preparado para ser executado usando Pandas, o método spark.sql() e os métodos do módulo pyspark.sql.\n",
        "\n",
        "O uso do *framework* Spark requer diversas configurações no ambiente de desenvolvimento para executar o *notebook*. Dado que tal complexidade foge do escopo de nossa disciplina, recomenda-se que o *notebook* seja executado na plataforma de desenvolvimento COLAB. O uso do COLAB  proporciona um ambiente de desenvolvimento pré-configurado e remove a complexidade de instalação e configuração de pacotes e *frameworks* que são utilizados na disciplina.\n",
        "\n",
        "**IMPORTANTE**\n",
        "\n",
        "**Antes de fazer a avaliação, leia atentamente a seção 5, que detalha instruções importantes sobre a avaliação e o critério de correção.**  \n",
        "\n",
        "**INSTRUÇÕES DE ENTREGA**\n",
        "\n",
        "**O que deve ser entregue:**\n",
        "- **O notebook com as respostas no formato .ipynb**\n",
        "- **O notebook com as respostas no formato .pdf**\n",
        "\n",
        "**Ambos arquivos devem ser nomeados usando o primeiro nome e o último sobrenome do aluno. Por exemplo: CristinaAguiar.ipynb e CristinaAguiar.pdf.**\n",
        "\n",
        "Boa avaliação!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3dN_WLQcyD"
      },
      "source": [
        "#1 Constelação de Fatos da BI Solutions\n",
        "\n",
        "A aplicação de *data warehousing* da BI Solutions utiliza como base uma constelação de fatos, conforme descrita a seguir.\n",
        "\n",
        "**Tabelas de dimensão**\n",
        "\n",
        "- data (dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno)\n",
        "- funcionario (funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla)\n",
        "- equipe (equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla)\n",
        "- cargo (cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel)\n",
        "- cliente (clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla)\n",
        "\n",
        "**Tabelas de fatos**\n",
        "- pagamento (dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamentos)\n",
        "- negociacao (dataPK, equipePK, clientePK, receita, quantidadeNegociacoes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGeh8KdXwVCQ"
      },
      "source": [
        "#2 Obtenção dos Dados da BI Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCCNC64AzBG0"
      },
      "source": [
        "## 2.1 Baixando o Módulo wget\n",
        "\n",
        "Para baixar os dados referentes ao esquema relacional da constelação de fatos da BI Solutions, é utilizado o módulo  **wget**. O comando a seguir realiza a instalação desse módulo. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e0Eao1K0EYG"
      },
      "source": [
        "#instalando o módulo wget\n",
        "%%capture\n",
        "!pip install -q wget\n",
        "!mkdir data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56pVJ2hZ2i5"
      },
      "source": [
        "## 2.2 Obtenção dos Dados das Tabelas de Dimensão\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de dimensão. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46QzTpLJwfkW",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1712e0d2-fe16-4af1-d29f-bfa995164ec8"
      },
      "source": [
        "#baixando os dados das tabelas de dimensão\n",
        "import wget\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv\"\n",
        "wget.download(url, \"data/data.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv\"\n",
        "wget.download(url, \"data/funcionario.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv\"\n",
        "wget.download(url, \"data/equipe.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv\"\n",
        "wget.download(url, \"data/cargo.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv\"\n",
        "wget.download(url, \"data/cliente.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/cliente.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o-dC7feszRc"
      },
      "source": [
        "## 2.3 Obtenção dos Dados Tabelas de Fatos\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de fatos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWM-CUFgBl_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbc79f12-09bc-4dfd-c80f-f1b51c69f52a"
      },
      "source": [
        "#baixando os dados das tabelas de fatos\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv\"\n",
        "wget.download(url, \"data/pagamento.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv\"\n",
        "wget.download(url, \"data/negociacao.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/negociacao.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO16-7-jOioq"
      },
      "source": [
        "# 3 Apache Spark Cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVEgY9qKflBV"
      },
      "source": [
        "## 3.1 Instalação\n",
        "\n",
        "Neste *notebook* é criado um *cluster* Spark composto apenas por um **nó mestre**. Ou seja, o *cluster* não possui um ou mais **nós de trabalho** e o **gerenciador de cluster**. Nessa configuração, as tarefas (*tasks*) são realizadas no próprio *driver* localizado no **nó mestre**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaM-OnIjgLS2"
      },
      "source": [
        "Para que o cluster possa ser criado, primeiramente é instalado o Java Runtime Environment (JRE) versão 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXls3bfoglKW"
      },
      "source": [
        "#instalando Java Runtime Environment (JRE) versão 8\n",
        "%%capture\n",
        "!apt-get remove openjdk*\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BQzZfDYhb4j"
      },
      "source": [
        "Na sequência, é feito o *download* do Apache Spark versão 3.0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_Yv59zg3gm"
      },
      "source": [
        "#baixando Apache Spark versão 3.0.0\n",
        "%%capture\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RETWX6wqhkLf"
      },
      "source": [
        "Na sequência, são configuradas as variáveis de ambiente JAVA_HOME e SPARK_HOME. Isto permite que tanto o Java quanto o Spark possam ser encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZpR7NwOh2EB"
      },
      "source": [
        "import os\n",
        "#configurando a variável de ambiente JAVA_HOME\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#configurando a variável de ambiente SPARK_HOME\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql0z7Ro1iHQb"
      },
      "source": [
        "Por fim, são instalados dois pacotes da linguagem de programação Python, cujas funcionalidades são descritas a seguir.\n",
        "\n",
        "> **Pacote findspark:** Usado para ler a variável de ambiente SPARK_HOME e armazenar seu valor na variável dinâmica de ambiente PYTHONPATH. Como resultado, Python pode encontrar a instalação do Spark. \n",
        "\n",
        "> **Pacote pyspark:** PySpark é a API do Python para Spark. Ela possibilita o uso de Python, considerando que o *framework* Apache Spark encontra-se desenvolvido na linguagem de programação Scala. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oSYOwKljPf5"
      },
      "source": [
        "%%capture\n",
        "#instalando o pacote findspark\n",
        "!pip install -q findspark==1.4.2\n",
        "#instalando o pacote pyspark\n",
        "!pip install -q pyspark==3.0.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAaLyjPzmIwZ"
      },
      "source": [
        "## 3.2 Conexão\n",
        "\n",
        "PySpark não é adicionado ao *sys.path* por padrão. Isso significa que não é possível importá-lo, pois o interpretador da linguagem Python não sabe onde encontrá-lo. \n",
        "\n",
        "Para resolver esse aspecto, é necessário instalar o módulo `findspark`. Esse módulo mostra onde PySpark está localizado. Os comandos a seguir têm essa finalidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zm1pBTEmjp4"
      },
      "source": [
        "#importando o módulo findspark\n",
        "import findspark\n",
        "#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n",
        "findspark.init()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDqfefF7YUab"
      },
      "source": [
        "Depois de configurados os pacotes e módulos e inicializadas as variáveis de ambiente, é possível iniciar o uso do Spark na aplicação de `data warehousing`. Para tanto, é necessário importar o comando `SparkSession` do módulo `pyspark.sql`. São utilizados os seguintes conceitos: <br>\n",
        "\n",
        "- `SparkSession`: permite a criação de `DataFrames`. Como resultado, as tabelas relacionais podem ser manipuladas por meio de `DataFrames` e é possível realizar consultas OLAP por meio de comandos SQL. <br>\n",
        "- `builder`: cria uma instância de SparkSession. <br>\n",
        "- `appName`: define um nome para a aplicação, o qual pode ser visto na interface de usuário web do Spark. <br> \n",
        "- `master`: define onde está o nó mestre do *cluster*. Como a aplicação é executada localmente e não em um *cluster*, indica-se isso pela *string* `local` seguida do parâmetro `[*]`. Ou seja, define-se que apenas núcleos locais são utilizados. \n",
        "- `getOrCreate`: cria uma SparkSession. Caso ela já exista, retorna a instância existente. \n",
        "\n",
        "\n",
        "**Observação**: A lista completa de todos os parâmetros que podem ser utilizados na inicialização do *cluster* pode ser encontrada neste [link](https://spark.apache.org/docs/latest/spark-standalone.html#cluster-launch-scripts)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxljJ_cwBCy"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IpYfoG_kx_8"
      },
      "source": [
        "# 4 Geração dos DataFrames em Pandas da BI Solutions\n",
        "\n",
        "Nesta seção são gerados os DataFrames em Pandas. Atenção aos nomes desses DataFrames. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arYf_PHlJCR"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw4NfyDZ--6z"
      },
      "source": [
        "cargoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv')\n",
        "clientePandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv')\n",
        "dataPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv')\n",
        "equipePandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv')\n",
        "funcionarioPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv')\n",
        "negociacaoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv')\n",
        "pagamentoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL9SiR_pQE2"
      },
      "source": [
        "# 5 Geração dos DataFrames em Spark da BI Solutions\n",
        "\n",
        "Nesta seção são gerados dos DataFrames em Spark. Atenção aos nomes desses DataFrames. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRVoz-SGt87W"
      },
      "source": [
        "## 5.1 Criação dos DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "FNR-3dV6oYk4"
      },
      "source": [
        "#criando os DataFrames em Spark \n",
        "cargo = spark.read.csv(path=\"data/cargo.csv\", header=True, sep=\",\")\n",
        "cliente = spark.read.csv(path=\"data/cliente.csv\", header=True, sep=\",\")\n",
        "data = spark.read.csv(path=\"data/data.csv\", header=True, sep=\",\")\n",
        "equipe = spark.read.csv(path=\"data/equipe.csv\", header=True, sep=\",\")\n",
        "funcionario = spark.read.csv(path=\"data/funcionario.csv\", header=True, sep=\",\")\n",
        "negociacao = spark.read.csv(path=\"data/negociacao.csv\", header=True, sep=\",\")\n",
        "pagamento = spark.read.csv(path=\"data/pagamento.csv\", header=True, sep=\",\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrch9vLgjl_H"
      },
      "source": [
        "## 5.2 Atualização dos Tipos de Dados "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A_ot2pOjsWB"
      },
      "source": [
        "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado inteiro. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmCV6Mur__z6"
      },
      "source": [
        "# identificando quais colunas de quais DataFrames devem ser do tipo de dado inteiro\n",
        "colunas_cargo = [\"cargoPK\"]\n",
        "colunas_cliente = [\"clientePK\"]\n",
        "colunas_data = [\"dataPK\", \"dataDia\", \"dataMes\", \"dataBimestre\", \"dataTrimestre\", \"dataSemestre\", \"dataAno\"]\n",
        "colunas_equipe = [\"equipePK\"]\n",
        "colunas_funcionario = [\"funcPK\", \"funcDiaNascimento\", \"funcMesNascimento\", \"funcAnoNascimento\"]\n",
        "colunas_negociacao = [\"equipePK\", \"clientePK\", \"dataPK\", \"quantidadeNegociacoes\"]\n",
        "colunas_pagamento = [\"funcPK\", \"equipePK\", \"dataPK\", \"cargoPK\", \"quantidadeLancamentos\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNnDJcG9R5H"
      },
      "source": [
        "# importando o tipo de dado desejado\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "\n",
        "# atualizando o tipo de dado das colunas especificadas \n",
        "# substituindo as colunas já existentes \n",
        "\n",
        "for coluna in colunas_cargo:\n",
        "  cargo = cargo.withColumn(coluna, cargo[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_cliente:\n",
        "  cliente = cliente.withColumn(coluna, cliente[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_data:\n",
        "  data = data.withColumn(coluna, data[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_equipe:\n",
        "  equipe = equipe.withColumn(coluna, equipe[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_funcionario:\n",
        "  funcionario = funcionario.withColumn(coluna, funcionario[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_negociacao:\n",
        "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_pagamento:\n",
        "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(IntegerType()))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0dX_7U_AzIY"
      },
      "source": [
        "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado número de ponto flutuante. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBcQ7Ep7AWqN"
      },
      "source": [
        "# identificando quais colunas de quais DataFrames devem ser do tipo de dado número de ponto flutuante\n",
        "colunas_negociacao = [\"receita\"]\n",
        "colunas_pagamento = [\"salario\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcfvkIK1BRSp"
      },
      "source": [
        "# importando o tipo de dado desejado\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "\n",
        "# atualizando o tipo de dado das colunas especificadas \n",
        "# substituindo as colunas já existentes \n",
        "\n",
        "for coluna in colunas_negociacao:\n",
        "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(FloatType()))\n",
        "\n",
        "for coluna in colunas_pagamento:\n",
        "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(FloatType()))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91nwfsV3_rKs"
      },
      "source": [
        "# importando funções adicionais \n",
        "from pyspark.sql.functions import round, desc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wN5iOGKwnHG"
      },
      "source": [
        "## 5.3 Criação de Visões Temporárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJsqRI3TwsjS"
      },
      "source": [
        "#criando as visões temporárias \n",
        "cargo.createOrReplaceTempView(\"cargo\")\n",
        "cliente.createOrReplaceTempView(\"cliente\")\n",
        "data.createOrReplaceTempView(\"data\")\n",
        "equipe.createOrReplaceTempView(\"equipe\")\n",
        "funcionario.createOrReplaceTempView(\"funcionario\")\n",
        "negociacao.createOrReplaceTempView(\"negociacao\")\n",
        "pagamento.createOrReplaceTempView(\"pagamento\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkL4w2MMudL7"
      },
      "source": [
        "# 6 Instruções Importantes sobre a Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKdDsHnDwlaH"
      },
      "source": [
        "## 6.1 Especificação das Consultas OLAP\n",
        "\n",
        "As consultas OLAP devem ser respondidas de acordo com o solicitado em cada questão. As seguintes solicitações podem ser feitas:\n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP usando **Pandas**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 05 da disciplina. Ou seja, a consulta deve ser respondida usando os métodos disponíveis na biblioteca Pandas para uso em Python. Não é possível usar o método `spark.sql()` para especificar a consulta. Também não é possível usar os demais métodos do módulo `pyspark.sql` para especificar a consulta.\n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP na **linguagem SQL**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 07 da disciplina. Ou seja, a consulta deve ser respondida usando a linguagem SQL textual e o método `spark.sql()`. Não é possível usar os métodos disponíveis na biblioteca Pandas para especificar a consulta. Também não é possível usar os demais métodos do módulo `pyspark.sql` para especificar a consulta, com exceção do método `show()` para listar o resultado da consulta. \n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP usando os **métodos de pyspark.sql**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 08 da disciplina. Ou seja, a consulta deve ser respondida usando os demais métodos do módulo `pyspark.sql`. Não é possível usar os métodos disponíveis na biblioteca Pandas para especificar a consulta. Também não é possível usar o método `spark.sql()` para especificar a consulta.\n",
        "\n",
        "**AVISO: Caso a consulta seja especificada de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsrYR2SJw-x3"
      },
      "source": [
        "## 6.2 Ordem das Colunas e das Linhas\n",
        "\n",
        "A resolução das questões deve seguir estritamente as especificações definidas em cada consulta. Isto significa que:\n",
        "\n",
        "- As **colunas** solicitadas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que todas as colunas a serem exibidas como resposta da consulta, bem como a ordem na qual elas devem aparecer são sempre definidas na questão. \n",
        "\n",
        "- As **linhas** retornadas como respostas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que a ordem na qual as linhas devem aparecer são sempre definidas na questão. \n",
        "\n",
        "- Os **nomes das colunas** renomeadas devem seguir estritamente os nomes definidos na questão. Para evitar possíveis erros, os nomes das colunas renomeadas não possuem acentos e espaços em branco, além de serem escritos utilizando apenas letras maiúsculas. Note que os nomes das colunas renomeadas são sempre definidos na questão.\n",
        "\n",
        "**AVISO: Essas orientações devem ser seguidas uma vez que a correção da avaliação será realizada de forma automática. Caso a consulta retorne resultados de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta.**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AZ0475X4L59"
      },
      "source": [
        "## 6.3 Listagem das Respostas das Consultas\n",
        "\n",
        "A resposta de cada consulta deve ser listada usando o método `show()`. Nenhum outro método pode ser utilizado com essa finalidade.  \n",
        "\n",
        "Devem ser listadas apenas as `25` primeiras linhas de resposta de cada consulta. Adicionalmente, devem ser listadas *strings* com tamanho maior do que 20 caracteres, ou seja, o parâmetro `truncate` do método `show()` deve ser inicializado como `false`.\n",
        "\n",
        "Portanto, a listagem das respostas deve ser feita utilizando o método `show()` como especificado a seguir. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize o comando `df.head(25)` para exibir o resultado da consulta.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize o comando `spark.sql(consultaSQL).show(25,truncate=False)` para exibir o resultado da consulta. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o comando `nomeDoDataFrame.show(25,truncate=False)` para exibir o resultado da consulta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzIcWYeOVOsN"
      },
      "source": [
        "## 6.4 Arredondamento dos Dados\n",
        "\n",
        "Deve ser realizado o arredondamento dos dados todas as vezes que uma função de agregação for aplicada às medidas numéricas `salario` da tabela de dimensão `pagamento` e `receita` da tabela de dimensão `negociacao`. \n",
        "\n",
        "O arredondamento deve ser realizado usando a função `round()` na linguagem SQL e o método `round()` em `pyspark.sql` e deve arredondar os dados até duas casas decimais. Por exemplo, podem ser produzidos resultados da forma `112233.4` e `112233.44`. \n",
        "\n",
        "Portanto, o arredondamento dos dados deve ser feito como especificado a seguir.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize o comando `df.round(2)` para arredondar os dados até duas casas decimais.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize a função `ROUND(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o método `round(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOtvy-LrJ32"
      },
      "source": [
        "## 6.5 Respostas das Questões\n",
        "\n",
        "As respostas das questões devem ser fornecidas de duas formas diferentes:\n",
        "\n",
        "- Exibidas na saída padrão.\n",
        "\n",
        "- Armazenadas em um arquivo no formato csv.\n",
        "\n",
        "A seguir são detalhadas as instruções em **Pandas**, **spark.sql()** e **pyspark()** para que as respostas sejam mostradas de forma apropriada para as correções. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drW2AS_V1MMr"
      },
      "source": [
        "Em **Pandas**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = consulta.round(2).head(25)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "display(QuestaoX)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX.to_csv(\"questaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaYNdTpk2PbL"
      },
      "source": [
        "**Em spark.sql()**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = spark.sql(query)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ... \n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "QuestaoX.show(25, truncate=False)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"questaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG8Y5lT72eCS"
      },
      "source": [
        "**Em pyspark()**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = consulta \n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "QuestaoX.show(25, truncate=False)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"QuestaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQVQqm0pNDS1"
      },
      "source": [
        "## 6.6 Comentários Explicativos\n",
        "\n",
        "Devem ser colocados comentários no código que expliquem o passo a passo da resolução da questão. Os comentários explicativos devem ser realizados como especificado a seguir. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize `#` para colocar comentário. Por exemplo:\n",
        "\n",
        "```\n",
        "# para a solução desta consulta OLAP, primeiramente é aplicado o método ... para ..... \n",
        "# Na sequência, é aplicado o método ... para ...\n",
        "```\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize `#` para colocar comentários gerais (conforme explicado para os demais métodos de `pyspark.sql`) ou utilize `--` para colocar comentários no comando SQL. Por exemplo:\n",
        "\n",
        "```\n",
        "# neste comentário são descritas as características de cada cláusula da consulta SQL. \n",
        "# A funcionalidade da cláusula SELECT nesta consulta é ... \n",
        "# A funcionalidade da cláusula FROM nesta consulta é ... \n",
        "# A funcionalidade da cláusula WHERE nesta consulta é ...\n",
        "```\n",
        "\n",
        "```\n",
        "-- A funcionalidade da cláusula SELECT nesta consulta é ...\n",
        "SELECT funcNome\n",
        "-- A funcionalidade da cláusula FROM nesta consulta é ...\n",
        "FROM funcionario\n",
        "-- A funcionalidade da cláusula WHERE nesta consulta é ...\n",
        "WHERE funcPK = 1\n",
        "```\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize `#` para colocar comentário. Por exemplo:\n",
        "\n",
        "```\n",
        "# para a solução desta consulta OLAP, primeiramente é aplicado o método ... para ..... \n",
        "# Na sequência, é aplicado o método ... para ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IcbpvZHPn3S"
      },
      "source": [
        "## 6.7 Indentação e Organização\n",
        "\n",
        "As consultas e os comandos que respondem às questões dessa avaliação devem ser escritos de forma indentada. Em caso de dúvida, observem os *notebooks* da Aula 05, da Aula 07 e da Aula 08 e verifiquem como as consultas e os comandos foram indentados.\n",
        "\n",
        "**AVISO: Com relação à organização, é necessário que as respostas às questões sejam localizadas aonde especificado no *notebook*. Por favor, procurem por \"Resposta da Questão\" para encontrar o local no qual as respostas devem ser especificadas. Também é possível localizar o local das respostas utilizando o menu de navegação.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFjCivy1Mg-A"
      },
      "source": [
        "## 6.8 Critério de Avaliação\n",
        "\n",
        "Na correção da avaliação, serão ponderados os seguintes aspectos:\n",
        "\n",
        "- Corretude da execução das consultas OLAP.\n",
        "\n",
        "- Atendimento às especificações definidas nas seções 6.1, 6.2, 6.3, 6.4, 6.5.\n",
        "\n",
        "- Atendimento às especificações da sintaxe das cláusulas e dos métodos utilizados para resolver cada questão.\n",
        "\n",
        "- Qualidade da documentação entregue, de acordo com as especificações definidas nas seções 6.6 e 6.7. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0pmgplPAL3"
      },
      "source": [
        "# 7 Consultas OLAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_emI31_-uYc5"
      },
      "source": [
        "O objetivo das consultas OLAP é realizar diferentes investigações sobre aspectos específicos no que tange às atividades realizadas pela BI Solutions. Os resultados obtidos nas investigações poderão ser posteriormente utilizados para a definição de estratégias que a empresa deve executar para prover melhorias. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CrGAAl0s6f4"
      },
      "source": [
        "## 7.1 Análises Relacionadas aos Cargos\n",
        "\n",
        "Foi identificado que, nos últimos anos, o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\" teve um aumento expressivo no que tange aos gastos com salários. O objetivo das análises desta seção é obter uma visão relacionada a esse aspecto, por meio da investigação dos gastos em salários considerando diferentes fatores. \n",
        "\n",
        "Podem ser realizadas diferentes análises, sendo que três delas são solicitadas a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zi-gqUljW18"
      },
      "source": [
        "### **Questão 1 (valor 1,0)**\n",
        "\n",
        "Liste, para cada ano, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando Pandas**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcSouuCk6N0-"
      },
      "source": [
        "### Resposta da Questão 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kKTtt-V6TKI"
      },
      "source": [
        "# Resposta da Questão 1 \n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .head()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FANzdCl6mAS"
      },
      "source": [
        "### **Questão 2 (valor: 1,0)**\n",
        "\n",
        "Liste, para cada nome da região da filial, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo nome da região em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpFnRTk369Q5"
      },
      "source": [
        "### Resposta da Questão 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQ-d4CJ7AEt"
      },
      "source": [
        "# Resposta da Questão 2\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj03JRHf7-am"
      },
      "source": [
        "### **Questão 3 (valor: 1,0)**\n",
        "\n",
        "Liste, por sexo, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"SEXO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo sexo em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando os métodos de pyspark.sql**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCpy46lL8Xdn"
      },
      "source": [
        "### Resposta da Questão 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq3uXrzT8jO-"
      },
      "source": [
        "# Resposta da Questão 3\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6s9Og_xCPc4"
      },
      "source": [
        "## 7.2 Análises Relacionadas às Regiões\n",
        "\n",
        "Foi identificada a necessidade de se investigar despesas e receitas no que tange às regiões. O objetivo das análises desta seção é obter uma visão relacionada a esse aspecto. \n",
        "\n",
        "Podem ser realizadas diferentes análises, sendo que três delas são solicitadas a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wy13GBocw36"
      },
      "source": [
        "### **Questão 4 (valor: 1,0)** \n",
        "\n",
        "Liste, para cada nome do estado da filial, a soma das receitas por ano considerando apenas o trimestre 1 e os clientes cuja região na qual eles moram é a mesma região na qual a filial está localizada. Arredonde a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ESTADO\", \"ANO\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro pelo total de receitas em ordem descendente, depois por estado em ordem descendente, depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando Pandas**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzhYPIvqnLc8"
      },
      "source": [
        "### Resposta da Questão 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd8CD2zLmnLe"
      },
      "source": [
        "# Resposta da Questão 4 \n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .head()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYHOKEoMaMg_"
      },
      "source": [
        "### **Questão 5 (valor: 1,0)** \n",
        "\n",
        "Liste, para cada nome da região da filial, a soma dos salários e a soma das receitas, considerando apenas o ano de 2017. Arredonde a soma dos salários e a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALRECEITAEQUIPE\", \"TOTALDESPESAEQUIPE\". Ordene as linhas exibidas primeiro pelo total de receitas em ordem descendente, depois pelo total de despesas ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Og3mkliav8c"
      },
      "source": [
        "### Resposta da Questão 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju_T2ILOa0Km"
      },
      "source": [
        "# Resposta da Questão 5\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzcUw0CYHPB1"
      },
      "source": [
        "### **Questão 6 (valor: 1,5)** \n",
        "\n",
        "Liste todas as agregações que podem ser geradas para a partir da soma dos salários por nome do estado da filial e por ano, considerando apenas o trimestre 1 e os funcionários cuja região na qual eles moram é a mesma região na qual a filial está localizada. Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ESTADO\", \"ANO\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro pelo total de receita em ordem descendente, depois por estado em ordem descendente, depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando os métodos de pyspark.sql.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBE_EVMnO0S"
      },
      "source": [
        "### Resposta da Questão 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiPX1LsrmqJS"
      },
      "source": [
        "# Resposta da Questão 6\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDhW4jqlZawA"
      },
      "source": [
        "## 7.3 Análise Relacionada a Totais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCRlYyOCZwRu"
      },
      "source": [
        "O objetivo da análise desta seção é obter uma tabela de totais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZNTAgi0hg1M"
      },
      "source": [
        "### **Questão 7 (valor: 1,5)** \n",
        "\n",
        "Liste, para cada nome da região da filial, o número total de funcionários diferentes, o número total de clientes diferentes e o número total de equipes diferentes. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALFUNCIONARIOS\", \"TOTALCLIENTES\", \"TOTALEQUIPES\". Ordene as linhas exibidas primeiro pela região em ordem descendente, depois pelo total de funcionários em ordem descendente, depois pelo total de clientes em ordem descendente, depois pelo total de equipes em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca8OOwWznQoS"
      },
      "source": [
        "### Resposta da Questão 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZzyESULmtIi"
      },
      "source": [
        "# Resposta da Questão 7\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgvlmwjQVBQm"
      },
      "source": [
        "# 8 Estendendo a Aplicação da BI Solutions\n",
        "\n",
        "A aplicação da BI Solutions está sendo estendida de forma a analisar um novo assunto de interesse: os gastos realizados na compra de equipamentos. Para tanto, é necessário criar uma nova tabela de dimensão chamada Equipamento, a qual tem como objetivo armazenar dados de equipamentos, os quais devem ser obtidos a partir de 3 fontes de dados heterogêneas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F8-VAlRYjvf"
      },
      "source": [
        "### 8.1 Detalhamento das Fontes  \n",
        "\n",
        "Considere que o processo de integração de dados já tenha sido realizado. Como resultado, as 3 fontes de dados (Fonte1, Fonte2, Fonte3) possuem os mesmos  atributos, com os mesmos nomes. Esses atributos encontram-se listados a seguir, sendo seus nomes semânticos.\n",
        "\n",
        "- equipamentoPK\n",
        "\n",
        "- equipamentoNome\n",
        "\n",
        "- equipamentoCor\n",
        "\n",
        "- equipamentoTipo\n",
        "\n",
        "- equipamentoMoeda\n",
        "\n",
        "- equipamentoPreco \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v879EQkZs--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "e2eb799e-b66d-4873-dd74-cb6bf8baf141"
      },
      "source": [
        "# Obtenção dos dados da Fonte1 e armazenamento desses dados no Dataframe chamado Fonte1\n",
        "Fonte1 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte1.csv')\n",
        "Fonte1.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>equipamentoPK</th>\n",
              "      <th>equipamentoNome</th>\n",
              "      <th>equipamentoDescricao</th>\n",
              "      <th>equipamentoCor</th>\n",
              "      <th>equipamentoTipo</th>\n",
              "      <th>equipamentoMoeda</th>\n",
              "      <th>equipamentoPreco</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>monitor</td>\n",
              "      <td>monitor LCD LG 15 polegadas</td>\n",
              "      <td>preto</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>EUR</td>\n",
              "      <td>39.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>monitor</td>\n",
              "      <td>monitor LCD ITAUTEC 19 polegadas</td>\n",
              "      <td>preto</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>180.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>monitor</td>\n",
              "      <td>monitor LCD AOC 17 polegadas</td>\n",
              "      <td>preto</td>\n",
              "      <td>Eequip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>167.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LENOVO THINKCENTRE MT-M W/ INTEL CORE 2 DUO @ ...</td>\n",
              "      <td>preto</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2399.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ITAUTEC INFOWAY SM 3322 W/ AMD PHENOM X2 8GB 3...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   equipamentoPK equipamentoNome  ... equipamentoMoeda equipamentoPreco\n",
              "0              1         monitor  ...              EUR            39.00\n",
              "1              2         monitor  ...              BRL           180.20\n",
              "2              3         monitor  ...              BRL           167.41\n",
              "3              5             NaN  ...              BRL          2399.41\n",
              "4              6             NaN  ...              NaN              nan\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzrqPkFkQOW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "f33cc126-d644-48b6-decb-34a65ab189b1"
      },
      "source": [
        "# Obtenção dos dados da Fonte2 e armazenamento desses dados no Dataframe chamado Fonte2\n",
        "Fonte2 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte2.csv')\n",
        "Fonte2.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>equipamentoPK</th>\n",
              "      <th>equipamentoNome</th>\n",
              "      <th>equipamentoDescricao</th>\n",
              "      <th>equipamentoCor</th>\n",
              "      <th>equipamentoTipo</th>\n",
              "      <th>equipamentoMoeda</th>\n",
              "      <th>equipamentoPreco</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>monitor</td>\n",
              "      <td>MONITOR LCD ITAUTEC 17 polegadas</td>\n",
              "      <td>PRETO</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>126.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>computador</td>\n",
              "      <td>LENOVO THINKCENTRE MT-M W/ INTEL CORE 2 DUO @ ...</td>\n",
              "      <td>PRETO</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2399.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>computador</td>\n",
              "      <td>HP COMPAQ DC5850 W/ AMD PHENOM X4 4GB RAM 250G...</td>\n",
              "      <td>PRATA</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1583.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>computador</td>\n",
              "      <td>HP COMPAQ DC5850 W/ AMD PHENOM X4 8GB RAM 250G...</td>\n",
              "      <td>PRETO</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>USD</td>\n",
              "      <td>250.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>computador</td>\n",
              "      <td>HP COMPAQ DC5850 W/ AMD PHENOM X4 16GB RAM 250...</td>\n",
              "      <td>PRATA</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2300.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   equipamentoPK equipamentoNome  ... equipamentoMoeda equipamentoPreco\n",
              "0              1         monitor  ...              BRL           126.35\n",
              "1              4      computador  ...              BRL          2399.41\n",
              "2             10      computador  ...              BRL          1583.74\n",
              "3             11      computador  ...              USD           250.00\n",
              "4             12      computador  ...              BRL          2300.74\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E--LvJfAQQ5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7913f631-5634-40e6-f3c6-e64b5d696282"
      },
      "source": [
        "# Obtenção dos dados da Fonte3 e armazenamento desses dados no Dataframe chamado Fonte3\n",
        "Fonte3 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte3.csv')\n",
        "Fonte3.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>equipamentoPK</th>\n",
              "      <th>equipamentoNome</th>\n",
              "      <th>equipamentoDescricao</th>\n",
              "      <th>equipamentoCor</th>\n",
              "      <th>equipamentoTipo</th>\n",
              "      <th>equipamentoMoeda</th>\n",
              "      <th>equipamentoPreco</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR LCD ITAUTEC 17 polegadas</td>\n",
              "      <td>prata</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>126.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>LENOVO THINKCENTRE MT-M W/ INTEL CORE 2 DUO @ ...</td>\n",
              "      <td>prata</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2399.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>ITAUTEC INFOWAY SM 3322 W/ AMD PHENOM X2 8GB 3...</td>\n",
              "      <td>prata</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1877.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>POSITIVO PLUS R70 W/ MOBO ITAUTEC SM3322 AMD P...</td>\n",
              "      <td>preto</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>3500.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>ITAUTEC INFOWAY ST 1430 W/ MB ITAUTEC SM3322 A...</td>\n",
              "      <td>prata</td>\n",
              "      <td>equip informatica</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1474.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   equipamentoPK equipamentoNome  ... equipamentoMoeda equipamentoPreco\n",
              "0              1         MONITOR  ...              BRL           126.35\n",
              "1              5      COMPUTADOR  ...              BRL          2399.41\n",
              "2              6      COMPUTADOR  ...              BRL          1877.84\n",
              "3              7      COMPUTADOR  ...              BRL          3500.47\n",
              "4              8      COMPUTADOR  ...              BRL          1474.87\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLR7_aLRWEGY"
      },
      "source": [
        "### 8.2 Detalhamento da tabela de dimensão Equipamento  \n",
        "\n",
        "A tabela de dimensão Equipamento da BI Solutions deve possuir os seguintes atributos:\n",
        "\n",
        "- **equipamentoPK**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoNome**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoDescricao**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoCor**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoTipo**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoPreco**, correspondente aos atributos equipamentoMoeda e equipamentoPreco nas fontes de dados. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54DBU9oSWkH0"
      },
      "source": [
        "### 8.3 Regras de Negócio do Processo de Integração de Instâncias\n",
        "\n",
        "No processo de integração de instâncias, devem ser consideradas as seguintes regras de negócio:\n",
        "\n",
        "- A integração deve ser feita pelo atributo equipamentoPK. Equipamentos que possuam o mesmo valor desse atributo referem-se ao mesmo equipamento.\n",
        "\n",
        "- Todas as *strings* devem ser escritas em letras maiúsculas, sem acento e sem o uso de caracteres especiais.\n",
        "\n",
        "- Os valores das *strings* não devem ser truncados.\n",
        "\n",
        "- Os preços dos equipamentos devem ser armazenados somente em reais. Portanto, para se calcular os valores da coluna equipamentoPreco da tabela de dimensão Equipamento, deve ser feito o cálculo desse valor em reais, utilizando os atributos equipamentoMoeda e equipamentoPreco presentes nas fontes de dados originais. Considere, para isso, as seguintes conversões: (i) 1 dolar USD = 5 reais; e (ii) 1 euro EUR = 6 reais.\n",
        "\n",
        "- Os preços dos equipamentos devem ter duas casas decimais e não devem incluir a sigla \"R$\". \n",
        "\n",
        "- As cores dos equipamentos devem ser armazenadas por meio de números, da seguinte forma:\n",
        "\n",
        "  - 1: correspondente à cor PRETO nas fontes de dados\n",
        "  - 2: correspondente à cor AZUL nas fontes de dados\n",
        "  - 3: correspondente à cor BRANCO nas fontes de dados\n",
        "  - 4: correspondente à cor PRATA nas fontes de dados\n",
        "  - 5: correspondente à cor VERMELHO nas fontes de dados\n",
        "  - 6: correspondente à cor AMARELO nas fontes de dados\n",
        "\n",
        "- Para resolver inconsistências nos valores de cada atributo que aparecem nas diferentes fontes, desconsidere os valores nulos e considere que: \n",
        "\n",
        "  - (i) quando em uma coluna o valor for igual nas três fontes, esse valor deve ser armazenado na tabela de dimensão Equipamento na coluna equivalente. Por exemplo, se o nome do equipamento de PK = 1 for caneta nas três fontes de dados, então o valor a ser armazenado é CANETA.\n",
        "\n",
        "  - (ii) quando em uma coluna o valor for igual em duas fontes e diferente na terceira fonte, o  valor a ser armazenado na tabela de dimensão Equipamento na coluna equivalente é o valor que aparece nas duas fontes. Por exemplo, se o nome do equipamento de PK = 1 for caneta em duas fontes de dados e borracha na terceira fonte de dados, então o valor a ser armazenado é CANETA.\n",
        "\n",
        "  - (iii) quando em uma coluna quando o valor for diferente nas três fontes, escolhe-se por armazenar o valor da Fonte 1 na tabela de dimensão Equipamento na coluna equivalente. Caso o valor da Fonte 1 seja nulo (inexistente), escolhe-se por armazenar o valor da Fonte 2. Caso o valor da Fonte 2 também seja nulo (inexistente), escolhe-se por armazenar o valor da Fonte 3. Isso significa que Fonte1 é mais confiável do que Fonte2, a qual é mais confiável do que Fonte3. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B_xyFc3IoJ9"
      },
      "source": [
        "### **Questão 8 (valor: 2,0)** \n",
        "\n",
        "Realize a geração da tabela de dimensão Equipamento, considerando os detalhamentos dos atributos das seções 8.1 e 8.2 e as regras de negócio do processo de integração de instâncias definido na seção 8.3. A tabela de dimensão Equipamento deve possuir as colunas na ordem e com os nomes especificados a seguir: equipamentoPK, equipamentoNome, equipamentoDescricao, equipamentoCor, equipamentoTipo, equipamentoPreco. Ordene as linhas exibidas pelo atributo equipamentoPK em ordem **ascendente**. Liste **todas** as linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão usando Pandas**. Coloque comentários detalhados explicando a sua resposta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzdJ-DJWaRaz"
      },
      "source": [
        "### Resposta da Questão 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAkH2AtVWzs-"
      },
      "source": [
        "# Resposta da Questão 7\n",
        "# Não se esqueça de finalizar a sua resposta mostrando seu resultado com .head()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão"
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}